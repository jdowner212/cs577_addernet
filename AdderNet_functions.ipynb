{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPttf/9esXXQ1wZhR332iQV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdowner212/cs577_addernet/blob/main/AdderNet_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import skimage\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "# so we can run original addernet:\n",
        "from torch.torch_version import TorchVersion\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "Q_XpZyGb_QSq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4LmN5vhI-2d7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Functions described in paper\n",
        "'''\n",
        "\n",
        "def L1(a,b):\n",
        "    return -1*np.abs(a-b)\n",
        "\n",
        "def hard_tanh(value):\n",
        "    if -1 < value and value < 1:\n",
        "        return value\n",
        "    elif value > 1:\n",
        "        return 1\n",
        "    elif value < -1:\n",
        "        return -1\n",
        "\n",
        "'''Equation 1'''\n",
        "# modified by Equation 2\n",
        "\n",
        "\n",
        "'''Equation 2'''\n",
        "def Y_adder(X, F, m, n, t, similarity_f=L1):\n",
        "    # assuming F.shape returns (#filters, #channels, #rows, #columns)\n",
        "    # assuming X.shape returns (#channels, #rows, #columns)\n",
        "    # assuming t specifies filter #\n",
        "    sum_ = 0\n",
        "    _, c_in, d, _ = F.shape     \n",
        "    for k in range(c_in):\n",
        "        for j in range(d):\n",
        "            for i in range(d):\n",
        "                sum_ += similarity_f(X[k, m+i, n+j], F[i, j, k, t])\n",
        "    return sum_\n",
        "\n",
        "'''Equation 3'''\n",
        "# ignore -- CNN formula\n",
        "\n",
        "'''Equation 4'''\n",
        "# ignore -- updated with equation 5\n",
        "\n",
        "'''Equation 5'''\n",
        "def dY_dF(X,F,m,n,i,j,k,t):\n",
        "    X_ = X[k,m+i,n+j]\n",
        "    F_ = F[t,k,i,j]\n",
        "    return X_ - F_\n",
        "\n",
        "'''Equation 6'''\n",
        "def dY_dX(X,F,m,n,i,j,k,t):\n",
        "    # clipped, full-precision gradient\n",
        "    X_ = X[k,m+i,n+j]\n",
        "    F_ = F[t,k,i,j]\n",
        "    return hard_tanh(X_ - F_)\n",
        "\n",
        "'''Equation 7'''\n",
        "# ignore -- hard_tanh implemented previously\n",
        "\n",
        "'''Equation 8'''\n",
        "# ignore -- CNN formula\n",
        "\n",
        "'''Equation 9'''\n",
        "# def var_Y_adder(X,F,variance_f=torch.var):\n",
        "    # check torch.var documentation: https://pytorch.org/docs/stable/generated/torch.var.html\n",
        "    # not sure if we can call torch.var(X) with default parameters\n",
        "    # or if we need to specify. Does this output a scalar or a tensor?\n",
        "# Trying K.var as tensorflow substitute for torch.var -- make sure they work the same\n",
        "# or tf.var?\n",
        "def var_Y_adder(X,F,variance_f=K.var):\n",
        "    var_X = variance_f(X)\n",
        "    var_F = variance_f(F)\n",
        "    ###\n",
        "    _, c_in, d, _ = F.shape\n",
        "    pi = np.pi\n",
        "\n",
        "    return np.sqrt(pi/2)*(d**2)*(c_in)*(var_X + var_F)\n",
        "\n",
        "'''Equation 10'''\n",
        "def batch_norm(minibatch, gamma, beta):\n",
        "    m = len(minibatch)\n",
        "    mean = (1/m)*sum(minibatch)\n",
        "    std = (1/m)*sum([(x_i-mean)**2 for x_i in minibatch])\n",
        "    gamma*(minibatch-mean)/std + beta\n",
        "    return gamma*(minibatch-mean)/std + beta\n",
        "\n",
        "'''Equation 11'''\n",
        "def dL_dMinibatch_i(minibatch,dL_dy,i,L,gamma):\n",
        "    # In dL_dy, y is the result of applying batch_norm to the minibatch\n",
        "    m = len(minibatch)\n",
        "    mean = (1/m)*sum(minibatch)\n",
        "    std = (1/m)*sum([(x_i-mean)**2 for x_i in minibatch])\n",
        "    \n",
        "    sum_ = 0\n",
        "    for j in range(m):\n",
        "        x_term = (minibatch[i]-minibatch[j])*(minibatch[j]-mean)/std\n",
        "        sum_ += (dL_dy[i] - dL_dy[j]*(1 + x_term))\n",
        "    sum_ *= gamma/((m**2)*std)\n",
        "    \n",
        "    return sum_\n",
        "\n",
        "'''Equation 12'''\n",
        "def delta_F_l(adaptive_lr_l, dL_dF_l, gamma):\n",
        "    # the update delta for the filter in layer l\n",
        "    return gamma*adaptive_lr_l*dL_dF_l\n",
        "\n",
        "'''Equation 13'''\n",
        "def adaptive_lr_l(dL_dF_l, eta, k):\n",
        "    # k = number of elements in F_l -- I think equal to len(dL_dF_1)\n",
        "    # in which case we don't need to explicitly provide it\n",
        "    \n",
        "    \n",
        "    # l2_norm = torch.sqrt([g**2 for g in dL_dF_l])\n",
        "    l2_norm = K.sqrt([g**2 for g in dL_dF_l]) # make sure torch.sqrt and K.sqrt are equivalents\n",
        "    \n",
        "    \n",
        "    return eta*np.sqrt(k)/l2_norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "most of original addernet -- I messed with it a bit trying \n",
        "to get it to work with tensorfow so not fully the original\n",
        "'''\n",
        "\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import numpy as np\n",
        "# from torch.autograd import Function\n",
        "# import math\n",
        "\n",
        "\n",
        "\n",
        "# loss           = mean_(layer_output[:,:,:,filter_index])\n",
        "# grads          = K.gradients(loss,model_input)[0]\n",
        "# grads          = grads / (sqrt_(mean_(square_(grads))) + 1e-5)\n",
        "# iterate        = K.function([model_input], [loss,grads])\n",
        "# input_img_data = np.random.random((1,size,size,3))*20+128\n",
        "\n",
        "# class adder(Function):\n",
        "\n",
        "@tf.function\n",
        "class my_adder:\n",
        "    @staticmethod\n",
        "    def forward(ctx, W_col, X_col):\n",
        "        ctx.save_for_backward(W_col,X_col)\n",
        "        output = -(W_col.unsqueeze(2)-X_col.unsqueeze(0)).abs().sum(1)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx,grad_output):\n",
        "        W_col,X_col = ctx.saved_tensors\n",
        "        grad_W_col = ((X_col.unsqueeze(0)-W_col.unsqueeze(2))*grad_output.unsqueeze(1)).sum(2)\n",
        "        grad_W_col = grad_W_col/grad_W_col.norm(p=2).clamp(min=1e-12)*math.sqrt(W_col.size(1)*W_col.size(0))/5\n",
        "        grad_X_col = (-(X_col.unsqueeze(0)-W_col.unsqueeze(2)).clamp(-1,1)*grad_output.unsqueeze(1)).sum(0)\n",
        "        \n",
        "        return grad_W_col, grad_X_col\n",
        "\n",
        "def adder2d_function(X, W, stride=1, padding=0):\n",
        "    n_filters, d_filter, h_filter, w_filter = W.size()\n",
        "    n_x, d_x, h_x, w_x = X.size()\n",
        "\n",
        "    h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
        "    w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
        "\n",
        "    h_out, w_out = int(h_out), int(w_out)\n",
        "    X_col = torch.nn.functional.unfold(X.view(1, -1, h_x, w_x), h_filter, dilation=1, padding=padding, stride=stride).view(n_x, -1, h_out*w_out)\n",
        "    X_col = X_col.permute(1,2,0).contiguous().view(X_col.size(1),-1)\n",
        "    W_col = W.view(n_filters, -1)\n",
        "    \n",
        "    out = adder.apply(W_col,X_col)\n",
        "    \n",
        "    out = out.view(n_filters, h_out, w_out, n_x)\n",
        "    out = out.permute(3, 0, 1, 2).contiguous()\n",
        "    \n",
        "    return out\n",
        "\n",
        "\n",
        "    \n",
        "class adder2d(tf.keras.layers.Layer):\n",
        "    def __init__(self,input_channel,output_channel,kernel_size, stride=1, padding=0, bias = False):\n",
        "        super(adder2d, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.adder = torch.nn.Parameter(nn.init.normal_(torch.randn(output_channel,input_channel,kernel_size,kernel_size)))\n",
        "        self.bias = bias\n",
        "        if bias:\n",
        "            self.b = torch.nn.Parameter(nn.init.uniform_(torch.zeros(output_channel)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = adder2d_function(x,self.adder, self.stride, self.padding)\n",
        "        if self.bias:\n",
        "            output += self.b.unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
        "        \n",
        "        return output\n",
        "    "
      ],
      "metadata": {
        "id": "XYJ9P5zmMZKy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.autograd import Function\n",
        "import math\n",
        "\n",
        "def adder2d_function(X, W, stride=1, padding=0):\n",
        "    n_filters, d_filter, h_filter, w_filter = W.size()\n",
        "    n_x, d_x, h_x, w_x = X.size()\n",
        "\n",
        "    h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
        "    w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
        "\n",
        "    h_out, w_out = int(h_out), int(w_out)\n",
        "    X_col = torch.nn.functional.unfold(X.view(1, -1, h_x, w_x), h_filter, dilation=1, padding=padding, stride=stride).view(n_x, -1, h_out*w_out)\n",
        "    X_col = X_col.permute(1,2,0).contiguous().view(X_col.size(1),-1)\n",
        "    W_col = W.view(n_filters, -1)\n",
        "    \n",
        "    out = adder.apply(W_col,X_col)\n",
        "    \n",
        "    out = out.view(n_filters, h_out, w_out, n_x)\n",
        "    out = out.permute(3, 0, 1, 2).contiguous()\n",
        "    \n",
        "    return out\n",
        "\n",
        "class adder(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, W_col, X_col):\n",
        "        ctx.save_for_backward(W_col,X_col)\n",
        "        output = -(W_col.unsqueeze(2)-X_col.unsqueeze(0)).abs().sum(1)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx,grad_output):\n",
        "        W_col,X_col = ctx.saved_tensors\n",
        "        grad_W_col = ((X_col.unsqueeze(0)-W_col.unsqueeze(2))*grad_output.unsqueeze(1)).sum(2)\n",
        "        grad_W_col = grad_W_col/grad_W_col.norm(p=2).clamp(min=1e-12)*math.sqrt(W_col.size(1)*W_col.size(0))/5\n",
        "        grad_X_col = (-(X_col.unsqueeze(0)-W_col.unsqueeze(2)).clamp(-1,1)*grad_output.unsqueeze(1)).sum(0)\n",
        "        \n",
        "        return grad_W_col, grad_X_col\n",
        "    \n",
        "class adder2d(nn.Module):\n",
        "\n",
        "    def __init__(self,input_channel,output_channel,kernel_size, stride=1, padding=0, bias = False):\n",
        "        super(adder2d, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.adder = torch.nn.Parameter(nn.init.normal_(torch.randn(output_channel,input_channel,kernel_size,kernel_size)))\n",
        "        self.bias = bias\n",
        "        if bias:\n",
        "            self.b = torch.nn.Parameter(nn.init.uniform_(torch.zeros(output_channel)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = adder2d_function(x,self.adder, self.stride, self.padding)\n",
        "        if self.bias:\n",
        "            output += self.b.unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "T9TGNNg8yhjZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Template '''\n",
        "\n",
        "\n",
        "# @tf.custom_gradient\n",
        "# def custom_op(inputs, activation, weights, biases):\n",
        "    \n",
        "#     # forward computation\n",
        "#     z = tf.matmul(inputs, weights) + biases\n",
        "#     if activation is not None:\n",
        "#         z = activation(result)\n",
        "    \n",
        "#     # backward computation\n",
        "#     def grad(upstream):\n",
        "#         inputs_gradient = tf.matmul(upstream, tf.transpose(weights))\n",
        "#         weights_gradient = tf.matmul(tf.transpose(inputs), upstream)\n",
        "#         bias_gradient = upstream\n",
        "#         return inputs_gradient, weights_gradient, bias_gradient\n",
        "    \n",
        "#     return z, grad"
      ],
      "metadata": {
        "id": "LA56AQMn7_9y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_n, f_d, f_h, f_w = 5,  3, 3, 3\n",
        "X_n, X_d, X_h, X_w = 10, 3, 5, 5\n",
        "\n",
        "F_rand  = np.random.random((f_n,f_d,f_h,f_w))\n",
        "F_torch = torch.tensor(F_rand)\n",
        "F_tf    = tf.convert_to_tensor(F_rand)\n",
        "\n",
        "X_rand  = np.random.random((X_n,X_d,X_h,X_w))\n",
        "X_torch = torch.tensor(X_rand)\n",
        "X_tf    = tf.convert_to_tensor(X_rand)"
      ],
      "metadata": {
        "id": "stlNhHik3RUa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_windows(tensor_of_images,k_d=3,k_w=3,k_h=3,stride=1,padding=0):\n",
        "    imgs = np.pad(tensor_of_images,pad_width=padding)\n",
        "    n = len(imgs)\n",
        "    return skimage.util.view_as_windows(imgs, (n,k_d,k_w,k_h), step=stride)\n",
        "\n",
        "\n",
        "# output from get_windows() has dimensions (A,B,C,D,E,F,G,H)\n",
        "#                                     e.g. (1,1,3,3,1,3,3,3)\n",
        "\n",
        "# A: a box - not sure what makes this not 1\n",
        "#     B: a box within a box - not sure what makes this not 1\n",
        "#         C: 3x3x3 windows for all rows and columns\n",
        "#            # i think reflects windows at a specific channel depth\n",
        "#            # and will be something other than one if input channels > filter channels\n",
        "#             D: 3x3x3 windows for a specific row of an image?\n",
        "#                # not sure how this will change with different # channels\n",
        "#                 E: a box within a box -- not sure what would make this value not 1\n",
        "#                     F: kxkxk -- a 3D window\n",
        "#                         G: kxk -- a channel of a 3D window\n",
        "#                             H: 1xk -- a row of a 3D window\n",
        "\n"
      ],
      "metadata": {
        "id": "2Uys-hZveTaY"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "scratch paper -- can probably ignore\n",
        "'''\n",
        "\n",
        "n_images, n_values, n_channels_in, new_H, new_W = new_images.shape\n",
        "\n",
        "p = 0\n",
        "s = 1\n",
        "W_ = int((W+2*p-k)/s+1)\n",
        "H_ = int((H+2*p-k)/s+1)\n",
        "n_channels_out = int((n_channels_in + 2*p - n_channels_in)+1)\n",
        "\n",
        "\n",
        "out = np.zeros((len(n_filters),n_channels_out, W_, H_))\n",
        "\n",
        "\n",
        "for f in n_filters:\n",
        "    for c in range(n_channels_out):\n",
        "        #print(f'Image {i+1}\\n')\n",
        "        for group in range(n_groups):\n",
        "            image_group = final_image[i][group]\n",
        "            added = (image_group + weight)\n",
        "            all_added=[]\n",
        "            for a in added:\n",
        "                all_added.append(K.sum(a))\n",
        "            print(sum(all_added))\n",
        "\n",
        "            #print(added.shape)\n",
        "            #print(added)\n",
        "            #print(K.sum(added,axis=2))\n",
        "            print('***')\n",
        "            #added = group + weights\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "XlyBLm9FLWP6",
        "outputId": "dcf86828-ce7b-4255-f4f6-7f3acbbc6ecf"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-225-a08209bfabe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_channels_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    }
  ]
}