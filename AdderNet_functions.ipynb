{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdowner212/cs577_addernet/blob/main/AdderNet_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "xJBCiQ6eoTki"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before running:\n",
        "\n",
        "1. Set `root` (below) to chosen directory"
      ],
      "metadata": {
        "id": "MHklBShmoUGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e0fhNZSGfHwc"
      },
      "outputs": [],
      "source": [
        "root = os.getcwd() # whatever you want"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Download CIFAR10 data"
      ],
      "metadata": {
        "id": "W3P8qFKGogvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "\n",
        "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "data_zip = os.path.join(root,'cifar-10-python.tar.gz')\n",
        "f = tarfile.open(data_zip)\n",
        "f.extractall(root) \n",
        "f.close()\n",
        "os.remove(data_zip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr8unJnXocpK",
        "outputId": "d40bb6e7-a18a-430b-97d5-f5a48136c643"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-16 03:22:02--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  85.9MB/s    in 1.9s    \n",
            "\n",
            "2022-11-16 03:22:04 (85.9 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q_XpZyGb_QSq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "#import tensorflow.keras.backend as K\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "import pickle\n",
        "import tensorflow.keras.utils as np_utils\n",
        "np_config.enable_numpy_behavior()\n",
        "from scipy.sparse import diags\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GcKuPTjCjLEo"
      },
      "outputs": [],
      "source": [
        "# def L1(a,b):\n",
        "#     return np.abs(a-b)\n",
        "\n",
        "def hard_tanh(array):\n",
        "    array = np.where(array<-1,-1,array)\n",
        "    array = np.where(array>1, 1, array)\n",
        "    return array\n",
        "\n",
        "def eps():\n",
        "    return np.random.uniform(1e-07,1e-06)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISUhuC_DB9_7"
      },
      "source": [
        "# Layer definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD9vhW-tCBj7"
      },
      "source": [
        "### `Layer` parent class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uH98VMolxy1J"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, upstream_g, learning_rate):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWAo_-8WCFZx"
      },
      "source": [
        "### `Adder` layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CnPeNX0zDoEQ"
      },
      "outputs": [],
      "source": [
        "# def adder_single_step(window, filter_, similarity_f=L1):\n",
        "#     \"\"\"\n",
        "#     window -- k_h x k_w x k_d\n",
        "#     filter -- k_h x k_w x k_d\n",
        "#     b      -- 1x1x1\n",
        "#     Z      -- scalar\n",
        "#     \"\"\"\n",
        "#     #H_k,W_k,D_k = filter_.shape\n",
        "#     #out=0\n",
        "#     #for h in range(H_k):\n",
        "#     #    for w in range(W_k):\n",
        "#     #        for d in range(D_k):\n",
        "#     #            out += similarity_f(window[h,w,d], filter_[h,w,d])\n",
        "#     return np.abs(window-filter_).sum()\n",
        "#     #return out\n",
        "\n",
        "class adder_layer(Layer):\n",
        "    def __init__(self,output_channels,kernel_size=3,stride=1,padding=0,adaptive_eta=0):\n",
        "        self.output_channels = output_channels\n",
        "        self.output_channels = output_channels\n",
        "        self.adaptive_eta=adaptive_eta\n",
        "        self.kernel_size=kernel_size        \n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.bias = np.zeros((1,1,1,self.output_channels))\n",
        "\n",
        "\n",
        "    def get_adaptive_lr(self, k, dfilters, eta):\n",
        "        \"\"\"    \n",
        "        k           -- n_tensors \n",
        "        dfilters    -- c_out x k_H x k_W x c_in\n",
        "        eta         -- scalar\n",
        "        \"\"\"\n",
        "        \n",
        "        norm = np.linalg.norm(dfilters, ord=2, axis=0)\n",
        "        return (eta * np.sqrt(k)) / (norm+eps())\n",
        "\n",
        "\n",
        "    def forward(self,X):\n",
        "        \"\"\"    \n",
        "        X       -- n_tensors x H x W x c_in\n",
        "        filters -- c_out x k_H x k_W x c_in\n",
        "        b       -- c_out x 1 x 1 x 1\n",
        "        Z       -- n_tensors x H_new x W_new, c_out\n",
        "        cache   -- info needed for backward pass\n",
        "        \"\"\"\n",
        "        self.input = X\n",
        "        self.input_channels = X.shape[-1]\n",
        "        self.filters = np.random.normal(loc=0,scale=1,size=(self.output_channels, self.kernel_size, self.kernel_size, self.input_channels))\n",
        "\n",
        "        filters,stride,padding,bias = self.filters, self.stride, self.padding, self.bias\n",
        "        n_tensors, H,   W,   c_in = X.shape\n",
        "        c_out,     H_k, W_k, c_in = filters.shape\n",
        "        n_filters = c_out\n",
        "\n",
        "        X_padded = np.pad(X, ((0,0), (padding,padding), (padding,padding), (0,0)), 'constant', constant_values = (0,0))\n",
        "        H_new = int((H + 2*padding - H_k)/stride)+1\n",
        "        W_new = int((W + 2*padding - W_k)/stride)+1\n",
        "\n",
        "        Z = np.zeros([n_tensors, H_new, W_new, c_out])\n",
        "\n",
        "        for i in range(n_tensors):           # traverse batch\n",
        "            this_img = X_padded[i,:,:,:]     # select ith image in batch\n",
        "            for f in range(n_filters):       # traverse filters\n",
        "                this_filter = filters[f,:,:,:]\n",
        "                #this_bias = bias[f,:,:,:]\n",
        "                for h in range(H_new):       # traverse height\n",
        "                    for w in range(W_new):   # traverse width\n",
        "                        \n",
        "                        v0,v1 = h*stride, h*stride + H_k\n",
        "                        h0,h1 = w*stride, w*stride + W_k\n",
        "                        \n",
        "                        this_window = this_img[v0:v1,h0:h1,:]\n",
        "\n",
        "                        Z[i, h, w, f] = np.abs(this_window-this_filter).sum()\n",
        "\n",
        "        assert Z.shape == (n_tensors, H_new, W_new, n_filters)\n",
        "\n",
        "        self.output = Z\n",
        "        self.cache = X, filters, bias, stride, padding\n",
        "        \n",
        "        return self.output\n",
        "\n",
        "    def backward(self, upstream_g, learning_rate):\n",
        "        \"\"\"\n",
        "        upstream_g (dL/dZ) -- n_tensors x H_up x W_up x c_up\n",
        "        cache (values from previous layers) -- (X, W, B, s, p)               \n",
        "        \n",
        "        Output:\n",
        "        dX -- dL/dX, shape n_tensors x H_down x W_down x c_down\n",
        "        dF -- dL/dW, shape n_filters x k x k x k\n",
        "        dB -- dL/dB, shape n_filters x 1 x 1 x 1\n",
        "        \"\"\"\n",
        "        \n",
        "        X, filters, bias, stride, padding = self.cache\n",
        "\n",
        "        n_tensors, H_down, W_down, c_down = X.shape\n",
        "        n_filters, H_k,    W_k,    c_down = filters.shape\n",
        "        n_tensors, H_up,   W_up,   c_up   = upstream_g.shape\n",
        "        \n",
        "        dX       = np.zeros_like(X)                           \n",
        "        dfilters = np.zeros_like(filters)\n",
        "        #dbias    = np.zeros((n_filters, 1,1,c_down))\n",
        "\n",
        "        X_padded  = np.pad(X,  ((0,0), (padding,padding), (padding,padding), (0,0)), 'constant', constant_values = (0,0))\n",
        "        dX_padded = np.pad(dX, ((0,0), (padding,padding), (padding,padding), (0,0)), 'constant', constant_values = (0,0))\n",
        "        \n",
        "        for i in range(n_tensors):                       \n",
        "            x = X_padded[i]\n",
        "            dx = dX_padded[i]\n",
        "            \n",
        "            for h in range(H_up):                   # traverse height\n",
        "                for w in range(W_up):               # traverse width\n",
        "                    for c in range(c_up):           # traverse filters\n",
        "                        \n",
        "                        v0,v1 = h,h+H_k\n",
        "                        h0,h1 = w,w+W_k\n",
        "                        \n",
        "                        x_window = x[v0:v1, h0:h1, :]\n",
        "                        f_window = filters[c,:,:,:]\n",
        "\n",
        "                        dx_local = hard_tanh(f_window-x_window)\n",
        "                        df_local = (x_window-f_window)\n",
        "\n",
        "                        g = upstream_g[i, h, w, c]\n",
        "\n",
        "                        dx[v0:v1, v0:v1, :] += dx_local * g\n",
        "                        dfilters[c,:,:,:]   += df_local * g\n",
        "                        #dbias[c,:,:,:]      += g\n",
        "                        \n",
        "            dX[i, :, :, :] = dx[padding:-padding, padding:-padding, :]\n",
        "        \n",
        "        assert(dX.shape == (n_tensors, H_down, W_down, c_down))\n",
        "\n",
        "\n",
        "        adaptive_lr = self.get_adaptive_lr(n_filters, dfilters, self.adaptive_eta)\n",
        "\n",
        "        self.filters -= learning_rate*adaptive_lr*dfilters\n",
        "        #self.bias    -= learning_rate*dbias\n",
        "\n",
        "        return dX\n",
        "\n",
        "\n",
        "    # def backward(self, upstream_g, learning_rate):\n",
        "    #     k = self.kernel_size\n",
        "    #     #window - filter\n",
        "    #     num  = (self.input - self.filters)*upstream_g.sum()\n",
        "    #     den = (num.norm(p=2).clamp(min=1e-012)*np.sqrt(k**2)).sum()\n",
        "\n",
        "    #     dW = ((self.input.unsqueeze(0)-self.filters.unsqueeze(2))*upstream_g.unsqueeze(1)).sum(2)\n",
        "    #     dW = num/den\n",
        "\n",
        "    #     dX = sum(-(self.input - self.filters).clamp(-1,1)*upstream_g)\n",
        "    #     #dW = dW/dW.norm(p=2).clamp(min=1e-12)*np.sqrt(self.filters.shape[1]*self.filters.size(0))/5\n",
        "    #     #dX = (-(self.input.unsqueeze(0)-self.filters.unsqueeze(2)).clamp(-1,1)*upstream_g.unsqueeze(1)).sum(0)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BztaNByshHDN"
      },
      "outputs": [],
      "source": [
        "def conv_single_step(window, filter_, bias):\n",
        "    \"\"\"\n",
        "    window -- k_h x k_w x k_d\n",
        "    filter_ -- k_h x k_w x k_d\n",
        "    b      -- 1x1x1\n",
        "    Z      -- scalar\n",
        "    \"\"\"\n",
        "    out = np.sum((np.multiply(window,filter_) + bias.astype(float))).astype(float)\n",
        "    \n",
        "    return out\n",
        "\n",
        "class conv_layer(Layer):\n",
        "    def __init__(self,output_channels,kernel_size=3,stride=1,padding=0):#,similarity_f = L1):\n",
        "        self.output_channels = output_channels\n",
        "\n",
        "\n",
        "        self.output_channels = output_channels\n",
        "        self.adaptive_eta=0\n",
        "\n",
        "        self.kernel_size=kernel_size        \n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,X):\n",
        "        \"\"\"    \n",
        "        X       -- n_tensors x H x W x c_in\n",
        "        filters -- c_out x k_H x k_W x c_in\n",
        "        b       -- c_out x 1 x 1 x 1\n",
        "        Z       -- n_tensors x H_new x W_new, c_out\n",
        "        cache   -- info needed for backward pass\n",
        "        \"\"\"\n",
        "        self.input = X\n",
        "\n",
        "        # in case input size not given\n",
        "        self.input_channels = X.shape[-1]\n",
        "\n",
        "        self.filters = np.random.normal(loc=0,scale=1,size=(self.output_channels, self.kernel_size, self.kernel_size, self.input_channels))\n",
        "        self.bias    = np.random.normal(loc=0,scale=1,size=(self.output_channels, 1,1,1))\n",
        "        \n",
        "        filters,stride,padding,bias = self.filters, self.stride, self.padding, self.bias\n",
        "        n_tensors, H,   W,   c_in = X.shape\n",
        "        c_out,     H_k, W_k, c_in = filters.shape\n",
        "        n_filters = c_out\n",
        "\n",
        "        X_padded = np.pad(X, ((0,0), (padding,padding), (padding,padding), (0,0)), 'constant', constant_values = (0,0))\n",
        "        H_new = int((H + 2*padding - H_k)/stride)+1\n",
        "        W_new = int((W + 2*padding - W_k)/stride)+1\n",
        "\n",
        "        Z = np.zeros([n_tensors, H_new, W_new, c_out])\n",
        "\n",
        "        for i in range(n_tensors):           # traverse batch\n",
        "            this_img = X_padded[i,:,:,:]     # select ith image in batch\n",
        "            for f in range(n_filters):       # traverse filters\n",
        "                this_filter = filters[f,:,:,:]\n",
        "                this_bias   = bias[f,:,:,:]\n",
        "                for h in range(H_new):       # traverse height\n",
        "                    for w in range(W_new):   # traverse width\n",
        "                        \n",
        "                        v0,v1 = h*stride, h*stride + H_k\n",
        "                        h0,h1 = w*stride, w*stride + W_k\n",
        "                        \n",
        "                        this_window = this_img[v0:v1,h0:h1,:]\n",
        "\n",
        "                        Z[i, h, w, f] = conv_single_step(this_window, this_filter, this_bias) \n",
        "\n",
        "        assert Z.shape == (n_tensors, H_new, W_new, n_filters)\n",
        "\n",
        "        self.output = Z\n",
        "        self.cache = X, filters, bias, stride, padding\n",
        "        \n",
        "        return self.output\n",
        "\n",
        "    def backward(self, upstream_g, learning_rate):\n",
        "        \"\"\"\n",
        "        upstream_g (dL/dZ) -- n_tensors x H_up x W_up x c_up\n",
        "        cache (values from previous layers) -- (X, W, B, s, p)               \n",
        "        \n",
        "        Output:\n",
        "        dX -- dL/dX, shape n_tensors x H_down x W_down x c_down\n",
        "        dF -- dL/dW, shape n_filters x k x k x k\n",
        "        dB -- dL/dB, shape n_filters x 1 x 1 x 1\n",
        "        \"\"\"\n",
        "        X, filters, bias, stride, padding = self.cache\n",
        "\n",
        "        n_tensors, H_down, W_down, c_down = X.shape\n",
        "        n_filters, H_k,    W_k,    c_down = filters.shape\n",
        "        n_tensors, H_up,   W_up,   c_up   = upstream_g.shape\n",
        "        \n",
        "        dX       = np.zeros_like(X)                           \n",
        "        dfilters = np.zeros_like(filters)\n",
        "        dbias    = np.zeros((n_filters, 1,1,1))\n",
        "\n",
        "        X_padded  = np.pad(X,  ((0,0), (padding,padding), (padding,padding), (0,0)), 'constant', constant_values = (0,0))\n",
        "        dX_padded = np.pad(dX, ((0,0), (padding,padding), (padding,padding), (0,0)), 'constant', constant_values = (0,0))\n",
        "        \n",
        "        for i in range(n_tensors):                       \n",
        "            x = X_padded[i]\n",
        "            dx = dX_padded[i]\n",
        "            \n",
        "            for h in range(H_up):                   # traverse height\n",
        "                for w in range(W_up):               # traverse width\n",
        "                    for c in range(c_up):           # traverse filters\n",
        "                        \n",
        "                        v0,v1 = h,h+H_k\n",
        "                        h0,h1 = w,w+W_k\n",
        "                        \n",
        "                        x_window = x[v0:v1, h0:h1, :]\n",
        "                        f_window = filters[c,:,:,:]\n",
        "\n",
        "                        dx_local = hard_tanh(f_window-x_window)\n",
        "                        df_local = x_window-f_window\n",
        "\n",
        "                        g = upstream_g[i, h, w, c]\n",
        "\n",
        "                        dx[v0:v1, v0:v1, :] += dx_local * g\n",
        "                        dfilters[c,:,:,:]   += df_local * g\n",
        "                        dbias[c,:,:,:]      += g\n",
        "                        \n",
        "            dX[i, :, :, :] = dx[padding:-padding, padding:-padding, :]\n",
        "        \n",
        "        assert(dX.shape == (n_tensors, H_down, W_down, c_down))\n",
        "\n",
        "        self.filters -= learning_rate*dfilters\n",
        "        self.bias    -= learning_rate*dbias\n",
        "\n",
        "        return dX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVevHrit5823"
      },
      "source": [
        "### Fully-connected layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ut73yN6458Nc"
      },
      "outputs": [],
      "source": [
        "class FullyConnected(Layer):\n",
        "    def __init__(self,output_channels):\n",
        "        super(Layer, self).__init__()\n",
        "        self.output_channels = output_channels\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.input = X\n",
        "        self.input_channels = X.shape[-1]\n",
        "        self.weights = np.random.normal(loc=0,scale=1,size=(self.input_channels,self.output_channels))\n",
        "        self.bias = np.random.normal(loc=0,scale=1,size=(X.shape[0], self.output_channels))\n",
        "        self.output = np.dot(self.input, self.weights) + self.bias\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, upstream_g, learning_rate):\n",
        "        dX    = np.dot(upstream_g, self.weights.T)\n",
        "        dW    = np.dot(self.input.T, upstream_g)\n",
        "        dbias = upstream_g\n",
        "\n",
        "        self.weights -= learning_rate*dW\n",
        "        self.bias    -= learning_rate*dbias\n",
        "\n",
        "        return dX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuAVweO_Apj4"
      },
      "source": [
        "### Flatten layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "J_v6tBkaArdE"
      },
      "outputs": [],
      "source": [
        "class Flatten(Layer):\n",
        "    def forward(self, X):\n",
        "        self.original_shape = X.shape\n",
        "        self.output = X.reshape(X.shape[0],np.product(X.shape[1:]))\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, upstream_g, learning_rate):\n",
        "        return upstream_g.reshape(self.original_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjpocIPJHz-0"
      },
      "source": [
        "### BatchNorm Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kpzQWoTFH1rv"
      },
      "outputs": [],
      "source": [
        "class batch_norm_layer(Layer):\n",
        "    def __init__(self, gamma=None,beta=None):\n",
        "\n",
        "        gamma = None if not gamma else gamma\n",
        "        self.gamma = gamma\n",
        "        beta = None if not beta else beta\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"    \n",
        "        X       -- n_tensors x H x W x c_in\n",
        "        gamma   -- n_tensors x 1 x 1 x 1\n",
        "        beta    -- n_tensors x 1 x 1 x 1\n",
        "        cache   -- info needed for backward pass\n",
        "        \"\"\"\n",
        "\n",
        "        self.input = X\n",
        "\n",
        "        self.gamma = np.ones((X.shape[0],1,1,1))\n",
        "        self.beta = np.zeros((X.shape[0],1,1,1))\n",
        "\n",
        "\n",
        "        mean = np.mean(X,axis=(0, 1, 2), keepdims=True)\n",
        "        var = np.mean(((X-mean)**2), axis=(0, 1, 2), keepdims=True)\n",
        "        std = np.sqrt(var)\n",
        "        \n",
        "        X_center = X - mean\n",
        "        X_norm = X_center/(std+eps())\n",
        "\n",
        "        self.output = X_norm*self.gamma + self.beta\n",
        "        self.cache = X, X_center, X_norm\n",
        "\n",
        "        return self.output \n",
        "\n",
        "\n",
        "    def backward(self, upstream_g, learning_rate):\n",
        "        \"\"\"\n",
        "        upstream_g (dL/dZ) -- n_tensors x H_up x W_up x c_up\n",
        "        cache (values from previous layers) -- (X, X_norm)               \n",
        "        \n",
        "        Output:\n",
        "        dX -- dL/dX, shape n_tensors x H_down x W_down x c_down\n",
        "        dF -- dL/dW, shape n_filters x k x k x k\n",
        "        dB -- dL/dB, shape n_filters x 1 x 1 x 1\n",
        "        \"\"\"\n",
        "\n",
        "        X, X_center, X_norm = self.cache\n",
        "\n",
        "        dGamma = np.sum(upstream_g * X_norm, axis=0)\n",
        "        dBeta = np.sum(upstream_g, axis=0)\n",
        "\n",
        "        m = len(X)\n",
        "        mean = np.mean(X)\n",
        "        std = np.std(X)\n",
        "        \n",
        "        dX = np.zeros_like(X)\n",
        "\n",
        "        for i in range(m):\n",
        "            for j in range(m):\n",
        "                dX[i] += (upstream_g[i] - upstream_g[j]*(1 + (X[i]-X[j])*(X[j]-mean)/std))\n",
        "        dX *= self.gamma/((m**2)*std)\n",
        "        \n",
        "        self.gamma = self.gamma - learning_rate*dGamma\n",
        "        self.beta  = self.beta  - learning_rate*dBeta\n",
        "\n",
        "        return dX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2t7dqw4ngiD"
      },
      "source": [
        "### Maxpool layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_zJEQA1fAzVS"
      },
      "outputs": [],
      "source": [
        "class MaxPool(Layer):\n",
        "    def __init__(self,pool_size=2):\n",
        "        self.pool_size=pool_size\n",
        "        self.stride = pool_size\n",
        "\n",
        "    def forward(self,X):\n",
        "        n_tensors, H, W, c_in = X.shape\n",
        "\n",
        "        H_new = int(1 + (H - self.pool_size) / self.stride)\n",
        "        W_new = int(1 + (W - self.pool_size) / self.stride)\n",
        "        c_out = c_in\n",
        "        \n",
        "        Z = np.zeros((n_tensors, H_new, W_new, c_out))              \n",
        "        \n",
        "        for i in range(n_tensors):                     # loop over the training examples\n",
        "            for h in range(H_new):                     # loop on the vertical axis of the output volume\n",
        "                for w in range(W_new):                 # loop on the horizontal axis of the output volume\n",
        "                    for c in range(c_out):             # loop over the channels of the output volume\n",
        "                        \n",
        "                        v0,v1 = h*self.stride, h*self.stride + self.pool_size\n",
        "                        h0,h1 = w*self.stride, w*self.stride + self.pool_size\n",
        "                        \n",
        "                        window = X[i, v0:v1, h0:h1,c]\n",
        "                    \n",
        "                        Z[i, h, w, c] = np.max(window)\n",
        "\n",
        "        self.output = Z\n",
        "        self.cache = X, self.pool_size, self.stride\n",
        "        \n",
        "        return self.output\n",
        "\n",
        "    def backward(self, upstream_g,learning_rate):\n",
        "        X, pool_size, stride = self.cache\n",
        "\n",
        "        n_tensors, H_down, W_down, c_down = X.shape\n",
        "        n_tensors, H_up,   W_up,   c_up   = upstream_g.shape\n",
        "\n",
        "\n",
        "        dX = np.zeros(X.shape)\n",
        "        \n",
        "        for i in range(n_tensors):                       \n",
        "            x = X[i]\n",
        "            for h in range(H_up):       \n",
        "            \n",
        "                for w in range(W_up):    \n",
        "                    for c in range(c_up):       \n",
        "                        v0,v1 = h, h+pool_size\n",
        "                        h0,h1 = w, w+pool_size\n",
        "\n",
        "                        x_window = x[v0:v1, h0:h1, c]\n",
        "                        \n",
        "                        local_g = np.where(x_window==np.max(x_window),1,0)\n",
        "                        g       = upstream_g[i, h, w, c]\n",
        "                         \n",
        "                        dX[i, v0:v1, h0:h1, c] += local_g * g\n",
        "\n",
        "        assert(dX.shape == X.shape)\n",
        "        \n",
        "        return dX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO7MWk0_B3XO"
      },
      "source": [
        "### Activation layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "jLa7JtufB6Tr"
      },
      "outputs": [],
      "source": [
        "def relu_fwd(X):\n",
        "    return np.where(X>=0,X,0)\n",
        "def relu_bwd(X):\n",
        "    return np.where(X>=0,1,0)\n",
        "\n",
        "def softmax_fwd(x):\n",
        "    soft = tf.nn.softmax(x)\n",
        "    return soft.numpy()\n",
        "\n",
        "def softmax_bwd(X): \n",
        "    s = softmax_fwd(X)\n",
        "    d = np.diag(s)\n",
        "    J = diags(d, shape=s.shape).toarray()\n",
        "\n",
        "    for i in range(len(J)):\n",
        "        for j in range(len(J[i])):\n",
        "            if i == j:\n",
        "                J[i][j] = s[i][j] * (1-s[i][j])\n",
        "            else: \n",
        "                J[i][j] = -s[i][j]*s[i][j]\n",
        "    return J\n",
        "\n",
        "def sig_fwd(X):\n",
        "    return 1/(1 + np.exp(-X))\n",
        "def sig_bwd(X):\n",
        "    return sig_fwd(X) * (1 - sig_fwd(X))\n",
        "\n",
        "activation_dict = {'relu':    {'forward':  relu_fwd,\n",
        "                               'backward': relu_bwd},\n",
        "                   'softmax': {'forward':  softmax_fwd,\n",
        "                               'backward': softmax_bwd},\n",
        "                   'sigmoid': {'forward':  sig_fwd,\n",
        "                               'backward': sig_bwd}}\n",
        "\n",
        "class Activation(Layer):\n",
        "    def __init__(self,activation_name):\n",
        "        super(Layer, self).__init__()\n",
        "        self.fwd=activation_dict[activation_name]['forward']\n",
        "        self.bwd=activation_dict[activation_name]['backward']\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.input = X\n",
        "        self.output = self.fwd(X)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, upstream_g, learning_rate):\n",
        "        local_g = self.bwd(self.input)\n",
        "        return local_g*upstream_g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKx4NGICC-74"
      },
      "source": [
        "### `Model` class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "iaEag2IkC-JR"
      },
      "outputs": [],
      "source": [
        "def cat_cross_entropy(y_true, y_pred):    \n",
        "    out = -np.mean(y_true*np.log(y_pred+eps()))\n",
        "    return out\n",
        "\n",
        "def cat_cross_entropy_prime(y_true,y_pred):\n",
        "    return np.mean([-y/(yhat+eps()) for (y,yhat) in zip(y_true,y_pred)])\n",
        "\n",
        "\n",
        "loss_dict = {'cat_cross_entropy':    {'forward':  cat_cross_entropy,\n",
        "                                      'backward': cat_cross_entropy_prime}}\n",
        "\n",
        "def get_mini_batches(X,y,batch_size):\n",
        "    mini_batches = []\n",
        "    for i in range(0,len(X), batch_size):\n",
        "        lower = i\n",
        "        upper = np.min([len(X), i + batch_size])\n",
        "        X_batch = X[lower:upper]\n",
        "        y_batch = y[lower:upper]\n",
        "        mini_batches.append((X_batch,y_batch))\n",
        "\n",
        "    return mini_batches\n",
        "\n",
        "class Model:\n",
        "    def __init__(self,loss_name): \n",
        "        self.layers = []\n",
        "        self.loss_fwd = loss_dict[loss_name]['forward']\n",
        "        self.loss_bwd = loss_dict[loss_name]['backward']\n",
        "\n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        y_hat = []\n",
        "        Z = input_data\n",
        "        for layer in self.layers:\n",
        "            Z = layer.forward(Z)\n",
        "        y_hat = Z\n",
        "        return y_hat\n",
        "\n",
        "    def fit(self, x_train, y_train, epochs, batch_size, learning_rate, x_val=None, y_val=None):\n",
        "        history = {'accuracy': [],'loss': [],'val_accuracy': [],'val_loss': []}\n",
        "\n",
        "        for e in range(epochs):\n",
        "            print(e)\n",
        "\n",
        "            loss_,acc,val_loss,val_acc=0,0,0,0\n",
        "\n",
        "            mini_batches = get_mini_batches(x_train,y_train, batch_size)\n",
        "\n",
        "            for i, mini_batch in enumerate(mini_batches):\n",
        "                \n",
        "                print(f'batch: {i+1}/{len(mini_batches)+1}')\n",
        "\n",
        "                x_batch, y_batch = mini_batch\n",
        "\n",
        "                # forward\n",
        "                Z = x_batch\n",
        "                for layer in self.layers:\n",
        "                    Z = layer.forward(Z)\n",
        "\n",
        "                y_real = y_batch\n",
        "                y_pred = Z\n",
        "\n",
        "                # compute loss and accuracy\n",
        "                loss_ += self.loss_fwd(y_real, y_pred)\n",
        "                acc   += sum(np.where(np.argmax(y_real,axis=1)==np.argmax(y_pred,axis=1),1,0))\n",
        "\n",
        "                # backward\n",
        "                error = self.loss_bwd(y_real, y_pred)\n",
        "                for layer in (self.layers)[::-1]:\n",
        "                    error = layer.backward(error, learning_rate)\n",
        "              \n",
        "            loss_ /= x_train.shape[0]\n",
        "            acc  /= x_train.shape[0]\n",
        "            \n",
        "            history['loss'].append(loss_)\n",
        "            history['accuracy'].append(acc)\n",
        "\n",
        "            if x_val is None or y_val is None:\n",
        "                print(f'Epoch: {e}   loss = {str(round(loss_,3))}   acc = {str(round(acc,3))}')\n",
        "            else:\n",
        "                Z_val = x_val\n",
        "                for layer in self.layers:\n",
        "                    Z_val = layer.forward(Z_val)\n",
        "\n",
        "                y_real_val = y_val\n",
        "                y_pred_val = Z_val\n",
        "\n",
        "                val_loss = self.loss_fwd(y_real_val, y_pred_val)\n",
        "                val_acc = sum(np.where(np.argmax(y_real_val,axis=1)==np.argmax(y_pred_val,axis=1),1,0))\n",
        "                val_acc  /= x_val.shape[0]                \n",
        "\n",
        "                history['val_accuracy'].append(val_acc)\n",
        "                history['val_loss'].append(val_loss)\n",
        "\n",
        "                print(f'Epoch: {e}   loss = {str(round(loss_,3))}   acc = {str(round(acc,3))}   val_loss = {str(round(val_loss,3))}   val_accuracy = {str(round(val_acc,3))}')\n",
        "\n",
        "        return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbHmgJRtCj69"
      },
      "source": [
        "## Data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oo5KOmoCzNm"
      },
      "source": [
        "### CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "uHl1tum3l-oL"
      },
      "outputs": [],
      "source": [
        "def load_cifar_data(folder,tiny=False):\n",
        "    train_batches = [f'{folder}/{f}' for f in os.listdir(folder) if 'batch_' in f]\n",
        "    test_batch    =  f'{folder}/test_batch'\n",
        "\n",
        "    # Get train data\n",
        "    X_trn = None\n",
        "    y_trn = []\n",
        "    for i in range(len(train_batches)):\n",
        "        train_data_dict = pickle.load(open(train_batches[i],'rb'), encoding='latin-1')\n",
        "        if i+1 == 1:\n",
        "            X_trn = train_data_dict['data']\n",
        "        else:\n",
        "            X_trn = np.vstack((X_trn, train_data_dict['data']))\n",
        "        y_trn += train_data_dict['labels']\n",
        "    X_trn = X_trn.reshape(len(X_trn),3,32,32)\n",
        "    X_trn = np.rollaxis(X_trn,1,4)\n",
        "    X_trn = X_trn.astype('float32')/255.0\n",
        "    y_trn = np_utils.to_categorical(np.asarray(y_trn),10)\n",
        "\n",
        "    # Get test data\n",
        "    test_data_dict  = pickle.load(open(test_batch,'rb'), encoding='latin-1')\n",
        "    X_tst = test_data_dict['data']\n",
        "    X_tst = X_tst.reshape(len(X_tst),3,32,32)\n",
        "    X_tst = np.rollaxis(X_tst,1,4)\n",
        "    X_tst = X_tst.astype('float32')/255.0\n",
        "    y_tst = np_utils.to_categorical(np.asarray(test_data_dict['labels']))\n",
        "    \n",
        "    n_90 = int(0.9*len(X_trn))\n",
        "    X_trn, X_val = X_trn[:n_90], X_trn[n_90:]\n",
        "    y_trn, y_val = y_trn[:n_90], y_trn[n_90:]\n",
        "\n",
        "    if tiny:\n",
        "        X_trn,y_trn,X_tst,y_tst,X_val,y_val = X_trn[:1000],y_trn[:1000],X_tst[:100],y_tst[:100],X_val[:100],y_val[:100]\n",
        "\n",
        "    return X_trn, y_trn, X_tst, y_tst, X_val, y_val\n",
        "\n",
        "data_dir = f'{root}/cifar-10-batches-py'\n",
        "X_trn_c10, y_trn_c10, X_tst_c10, y_tst_c10, X_val_c10, y_val_c10 = load_cifar_data(data_dir,tiny=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kRIJNY0dRvD2"
      },
      "outputs": [],
      "source": [
        "this_model = Model(loss_name='cat_cross_entropy')\n",
        "\n",
        "this_model.add(adder_layer(output_channels=8,kernel_size=3,stride=1,padding=1,adaptive_eta=0.1))\n",
        "this_model.add(Activation('relu'))\n",
        "this_model.add(MaxPool(pool_size=2))\n",
        "this_model.add(batch_norm_layer())\n",
        "\n",
        "this_model.add(Flatten())\n",
        "\n",
        "this_model.add(FullyConnected(output_channels=64))\n",
        "this_model.add(Activation('relu'))\n",
        "this_model.add(FullyConnected(output_channels=10))\n",
        "this_model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBl1GKVe9MCg",
        "outputId": "0aa58255-1499-4e45-f36d-ff58eb49ea74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n",
            "Epoch: 0   loss = 0.021   acc = 0.094   val_loss = 1.286   val_accuracy = 0.17\n",
            "1\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n",
            "Epoch: 1   loss = 0.021   acc = 0.087   val_loss = 1.259   val_accuracy = 0.15\n",
            "2\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n",
            "Epoch: 2   loss = 0.021   acc = 0.097   val_loss = 1.268   val_accuracy = 0.11\n",
            "3\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n",
            "Epoch: 3   loss = 0.021   acc = 0.098   val_loss = 1.295   val_accuracy = 0.12\n",
            "4\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n",
            "Epoch: 4   loss = 0.021   acc = 0.095   val_loss = 1.28   val_accuracy = 0.1\n",
            "5\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n",
            "Epoch: 5   loss = 0.021   acc = 0.11   val_loss = 1.314   val_accuracy = 0.09\n",
            "6\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n",
            "Epoch: 6   loss = 0.02   acc = 0.124   val_loss = 1.341   val_accuracy = 0.07\n",
            "7\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n",
            "Epoch: 7   loss = 0.021   acc = 0.095   val_loss = 1.423   val_accuracy = 0.05\n",
            "8\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n",
            "Epoch: 8   loss = 0.021   acc = 0.108   val_loss = 1.274   val_accuracy = 0.1\n",
            "9\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n",
            "Epoch: 9   loss = 0.021   acc = 0.106   val_loss = 1.249   val_accuracy = 0.11\n",
            "10\n",
            "batch: 1/17\n",
            "batch: 2/17\n",
            "batch: 3/17\n",
            "batch: 4/17\n",
            "batch: 5/17\n",
            "batch: 6/17\n",
            "batch: 7/17\n",
            "batch: 8/17\n",
            "batch: 9/17\n",
            "batch: 10/17\n",
            "batch: 11/17\n",
            "batch: 12/17\n",
            "batch: 13/17\n",
            "batch: 14/17\n",
            "batch: 15/17\n",
            "batch: 16/17\n"
          ]
        }
      ],
      "source": [
        "history = this_model.fit(X_trn_c10,y_trn_c10,epochs=20,batch_size=64,learning_rate=1e-01,x_val=X_val_c10,y_val=y_val_c10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(range(20),history['accuracy'],label='train')\n",
        "plt.plot(range(20),history['val_accuracy'],label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.xticks(range(0,21,2))\n",
        "plt.ylim(0,0.3)\n",
        "plt.title('Accuracy -- our AdderNet implementation')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "XI4_IdBIqhNy",
        "outputId": "91c52132-2bd7-467d-c347-9852fb42b5d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5d58400dd544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(range(20),history['loss'],label='train')\n",
        "plt.plot(range(20),history['val_loss'],label='val')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.xticks(range(0,21,2))\n",
        "plt.ylim(0,0.1)\n",
        "plt.title('Loss -- our AdderNet implementation')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "2CDP87ePA6ji",
        "outputId": "4ee91f37-f2c3-4c5c-9de1-af925d8f960e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this_model = Model(loss_name='cat_cross_entropy')\n",
        "# l1 = X_trn_c10\n",
        "# l1=adder_layer(output_channels=8,kernel_size=3,stride=1,padding=1).forward(l1)\n",
        "# print(l1.shape)\n",
        "# l2=Activation('relu').forward(l1)\n",
        "# print(l2.shape)\n",
        "# l3=MaxPool(pool_size=2).forward(l2)\n",
        "# print(l3.shape)\n",
        "# l4=batch_norm_layer().forward(l3)\n",
        "# print(l4.shape)\n",
        "\n",
        "# l5=Flatten().forward(l4)\n",
        "# print(l5.shape)\n",
        "# l6=FullyConnected(output_channels=64).forward(l5)\n",
        "# print(l6.shape)\n",
        "# l7=Activation('relu').forward(l6)\n",
        "# print(l7.shape)\n",
        "# l8=FullyConnected(output_channels=10).forward(l7)\n",
        "# print(l8.shape)\n",
        "# l9=Activation('softmax').forward(l8)\n",
        "# print(l9.shape)"
      ],
      "metadata": {
        "id": "W8_z0zzAqNIK"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8Yv10oyGM8U"
      },
      "outputs": [],
      "source": [
        "cnn = Model(loss_name='cat_cross_entropy')\n",
        "\n",
        "cnn.add(conv_layer(output_channels=8,kernel_size=3,stride=1,padding=1))\n",
        "cnn.add(Activation('relu'))\n",
        "cnn.add(MaxPool(pool_size=2))\n",
        "cnn.add(batch_norm_layer())\n",
        "\n",
        "\n",
        "cnn.add(Flatten())\n",
        "\n",
        "cnn.add(FullyConnected(output_channels=64))\n",
        "cnn.add(Activation('relu'))\n",
        "cnn.add(FullyConnected(output_channels=10))\n",
        "cnn.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9rx3vWnGPFM"
      },
      "outputs": [],
      "source": [
        "cnn.fit(X_trn_c10,y_trn_c10,10,1e-05,X_val_c10,y_val_c10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sfJxcQWhwqV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}